{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\margl1440\margr1440\vieww18520\viewh15100\viewkind0
\deftab560
\pard\pardeftab560\slleading20\partightenfactor0

\f0\fs26 \cf0 # prepare temporary storage space\
rm -r /app/DATASET/temp_for_dataset\
mkdir /app/DATASET/temp_for_dataset\
\pard\pardeftab560\slleading20\pardirnatural\partightenfactor0
\cf0 \
\pard\pardeftab560\slleading20\partightenfactor0
\cf0 # get which images were part of test/train/val partitions\
cd /app/CLIP-LoRA-Species-Mapping/\
python sim_main.py \\\
	--root_path <human labels DIR> \\\
	--dataset gsv \\\
	--seed 1 \\\
	--shots 100000000000000 \\\
	--backbone "bioclip" \\\
	--n_iters 50 \\\
	--subsample_amount 1000 \\\
	--save_path /app/DATASET/temp_for_dataset\
\
# create COCO file for human trained data and put the rest of the images in a file for machine annotation\
python split_test.py \\\
	--tranches <human labels instances_default.json> \\\
	--images <human labels images> \\\
	--output /app/DATASET/temp_for_dataset/ \\\
	--tested_on /app/DATASET/temp_for_dataset/images_tested_on.txt \\\
	--trained_on /app/DATASET/temp_for_dataset/images_trained_on.txt\
\
# get machine labels\
python image_annotater.py \\\
	--lora_path "/app/DATASET/figures/fig2_bioclip/subsample_$\{i\}/bio_clip/gsv/\cf2 \CocoaLigature0 100000000000000shots/seed1/lora_weights.pt" \\\
	--image_dir <machine labels images> \\\
	--output_file /app/DATASET/temp_for_dataset/pure_machine.json \\\
	--encoder both\
	--backbone bio_clip\
\
\pard\pardeftab560\slleading20\partightenfactor0
\cf0 \CocoaLigature1 python image_annotater.py \\\
	--lora_path "/app/DATASET/figures/fig2_bioclip/subsample_$\{i\}/bio_clip/gsv/\cf2 \CocoaLigature0 100000000000000shots/seed1/lora_weights.pt" \\\
	--image_dir /app/DATASET/temp_for_dataset/reject/ \\\
	--output_file /app/DATASET/temp_for_dataset/human_relabeled.json \\\
	--encoder both\
	--backbone bio_clip\
\
# merge COCO files\
python coco_merger.py \\\
	--tranches /app/DATASET/temp_for_dataset/train_human.json /app/DATASET/temp_for_dataset/pure_machine.json /app/DATASET/temp_for_dataset/human_relabeled.json \\\
	--output /app/DATASET/temp_for_dataset/merged_for_train_val.json\
\
# clean out previous iteration just in case\
rm -r <all labels species_classification_vectors>\
\
# create train/val split\
cd /app/SpeciesMapping/multi_level_dataset_scripts/\
python integrate_species_classification.py \\\
	--dataset_dir <all labels DIR> \\\
	--coco_file /app/DATASET/temp_for_dataset/merged_for_train_val.json \\\
	--output_dir <all labels DIR> \\\
	--ratio_train 0.9 \\\
	--ratio_val 0.1\
\
# ensure we use the right test set\
cp <human labeled test set> <all labels test set>\
\
# prep the final COCO file\
\cf0 \CocoaLigature1 cd /app/CLIP-LoRA-Species-Mapping/\cf2 \CocoaLigature0 \
python coco_merger.py \\\
	--tranches /app/DATASET/temp_for_dataset/merged_for_train_val.json /app/DATASET/temp_for_dataset/test.json \\\
	--output <all labels instances_default.json>\
\
# run s2 training\
cd /app/SpeciesMapping/s2_features_training/\
python train_one_species.py \\\
	--dataset_dir <all labels DIR> \\\
	--test_dataset_dir <all labels DIR> \\\
	--save_dir "/app/DATASET/figures/fig3_$\{i\}shot/Azadiractha_Indica/ \\\
	--species_id 24 \\\
	--hidden_dims 512 256 128 \\\
	--learning_rate 0.0001\
\
\
\
\
\
 }