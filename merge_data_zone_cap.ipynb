{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as cocomask\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/75326066/coco-annotations-convert-rle-to-polygon-segmentation\n",
    "def rle_to_coco(annotation: dict) -> list[dict]:\n",
    "    \"\"\"Transform the rle coco annotation (a single one) into coco style.\n",
    "    In this case, one mask can contain several polygons, later leading to several `Annotation` objects.\n",
    "    In case of not having a valid polygon (the mask is a single pixel) it will be an empty list.\n",
    "    Parameters\n",
    "    ----------\n",
    "    annotation : dict\n",
    "        rle coco style annotation\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict]\n",
    "        list of coco style annotations (in dict format)\n",
    "    \"\"\"\n",
    "\n",
    "    annotation[\"segmentation\"] = cocomask.frPyObjects(\n",
    "        annotation[\"segmentation\"],\n",
    "        annotation[\"segmentation\"][\"size\"][0],\n",
    "        annotation[\"segmentation\"][\"size\"][1],\n",
    "    )\n",
    "\n",
    "    maskedArr = cocomask.decode(annotation[\"segmentation\"])\n",
    "    contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    segmentation = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if contour.size >= 6:\n",
    "            segmentation.append(contour)\n",
    "\n",
    "    if len(segmentation) == 0:\n",
    "        annotation[\"segmentation\"] = []\n",
    "\n",
    "    else:\n",
    "        # annotation[\"bbox\"] = annotation[\"segmentation\"][\"bbox\"]\n",
    "        # annotation[\"area\"] = annotation[\"segmentation\"][\"area\"]\n",
    "        annotation[\"segmentation\"] = []\n",
    "        for i, seg in enumerate(segmentation):\n",
    "            annotation[\"segmentation\"].append(\n",
    "                seg.astype(float).flatten().tolist()\n",
    "            )\n",
    "            # annotation[\"bbox\"] = list(cv2.boundingRect(seg))\n",
    "            # annotation[\"area\"] = cv2.contourArea(seg)\n",
    "            # annotation[\"instance_id\"] = annotation[\"id\"]\n",
    "            # annotation[\"id\"] = f\"{annotation['id']}_{i}\"\n",
    "            # single_annotation.pop(\"segmentation\")\n",
    "\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLabel(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.ann_count = {}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        coco = self.coco\n",
    "        # Image ID\n",
    "        img_id = self.ids[index]\n",
    "        # List: get annotation id from coco\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        # Dictionary: target coco_annotation file for an image\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        # path for input image\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        # open the input image\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "\n",
    "        # number of objects in the image\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor([img_id])\n",
    "        # Size of bbox (Rectangular)\n",
    "        areas = []\n",
    "        for i in range(num_objs):\n",
    "            areas.append(coco_annotation[i]['area'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def get_ann_counts(self):\n",
    "        coco = self.coco\n",
    "        for i in range(len(self.ids)):\n",
    "            self.ann_count[self.ids[i]] = 0\n",
    "\n",
    "        for i in range(len(self.ids)):\n",
    "            ann_ids = coco.getAnnIds(imgIds=self.ids[i])\n",
    "            # Dictionary: target coco_annotation file for an image\n",
    "            coco_annotation = coco.loadAnns(ann_ids)\n",
    "            for ann in coco_annotation:\n",
    "                if (ann['iscrowd'] == 1):\n",
    "                    self.ann_count[int(ann['image_id'])] += 1\n",
    "\n",
    "    \n",
    "    def export_images(self, offset: int, select, state: str = None):\n",
    "        exp = []\n",
    "        coco = self.coco\n",
    "        for i in select:\n",
    "            self.ann_count[self.ids[i]] = 0\n",
    "            img = coco.loadImgs(self.ids[i])[0]\n",
    "            img['id'] = int(img['id']) + offset\n",
    "            img.pop('flickr_url')\n",
    "            img.pop('coco_url')\n",
    "            img.pop('date_captured')\n",
    "            if state is not None:\n",
    "                img['state'] = state\n",
    "\n",
    "            ann_ids = coco.getAnnIds(imgIds=self.ids[i])\n",
    "            coco_annotation = coco.loadAnns(ann_ids)\n",
    "            if len(coco_annotation) > 0:\n",
    "                exp.append(img)\n",
    "        \n",
    "        return exp\n",
    "    \n",
    "    def export_annotations(self, offset: int, select, img_offset: int):\n",
    "        exp = []\n",
    "        coco = self.coco\n",
    "        for i in select:\n",
    "            ann_ids = coco.getAnnIds(imgIds=self.ids[i])\n",
    "            # Dictionary: target coco_annotation file for an image\n",
    "            coco_annotation = coco.loadAnns(ann_ids)\n",
    "            for ann in coco_annotation:\n",
    "                self.ann_count[int(ann['image_id'])] += 1\n",
    "                ann['id'] = int(ann['id']) + offset\n",
    "                ann['image_id'] = int(ann['image_id']) + img_offset\n",
    "                \n",
    "                if (ann['iscrowd'] == 1):\n",
    "                    ann['iscrowd'] = 0 # so we can train on it\n",
    "                    ann = rle_to_coco(ann)\n",
    "                    if len(ann[\"segmentation\"]) > 0:\n",
    "                        exp.append(ann)\n",
    "                    \n",
    "                else:\n",
    "                    print(ann['segmentation'])\n",
    "        \n",
    "        return exp\n",
    "    \n",
    "    def export_mask(self, output_dir: str):\n",
    "        for id in range(len(self.ids)):\n",
    "            coco = self.coco\n",
    "            ann_ids = coco.getAnnIds(imgIds=self.ids[id])\n",
    "            path = coco.loadImgs(self.ids[id])[0]['file_name']\n",
    "            # open the input image\n",
    "            img = Image.open(os.path.join(self.root, path))\n",
    "\n",
    "            mask_img = Image.new('L', (img.width, img.height), 0)\n",
    "            \n",
    "            # Dictionary: target coco_annotation file for an image\n",
    "            coco_annotation = coco.loadAnns(ann_ids)\n",
    "            for ann in coco_annotation:\n",
    "                for poly in ann['segmentation']:\n",
    "                    ImageDraw.Draw(mask_img, 'L').polygon(poly, fill=(255))\n",
    "            \n",
    "            mask_img.save(os.path.join(output_dir, path))\n",
    "\n",
    "    def prep_zone_buckets(self, zones, csv):\n",
    "        self.by_zone = {}\n",
    "        for zone in zones:\n",
    "            self.by_zone[zone] = []\n",
    "\n",
    "        csv = pd.read_csv(csv)\n",
    "        img_map = {}\n",
    "        for _, row in csv.iterrows():\n",
    "            img_map[row['filename']] = row['zone']\n",
    "\n",
    "        for id in range(len(self.ids)):\n",
    "            coco = self.coco\n",
    "            ann_ids = coco.getAnnIds(imgIds=self.ids[id])\n",
    "            path = coco.loadImgs(self.ids[id])[0]['file_name']\n",
    "\n",
    "            if len(ann_ids) > 0 and path in img_map and img_map[path] in zones:\n",
    "                self.by_zone[img_map[path]].append(id)\n",
    "        \n",
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../Treework/filtered_imported_data/CaliforniaTrees7', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees0', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees1', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees6', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees8', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees3', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees4', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees5', 'California'), ('../Treework/filtered_imported_data/CaliforniaTrees2', 'California')]\n"
     ]
    }
   ],
   "source": [
    "# get all directories to copy over\n",
    "dirs = []\n",
    "\n",
    "for file in os.listdir('../Treework/filtered_imported_data'):\n",
    "    if file == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    if file[:file.find(\"Trees\")] == 'California':\n",
    "        dirs.append((f'../Treework/filtered_imported_data/{file}', file[:file.find(\"Trees\")]))\n",
    "\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "4a 0\n",
      "4b 0\n",
      "5a 0\n",
      "5b 23\n",
      "6a 1048\n",
      "6b 999\n",
      "7a 1123\n",
      "7b 949\n",
      "8a 1047\n",
      "8b 943\n",
      "9a 847\n",
      "9b 1027\n",
      "10a 1051\n",
      "10b 803\n",
      "11a 20\n",
      "11b 0\n"
     ]
    }
   ],
   "source": [
    "zones = ['4a', '4b', '5a', '5b', '6a', '6b', '7a', '7b', '8a', '8b', '9a', '9b', '10a', '10b', '11a', '11b']\n",
    "zone_counts = {}\n",
    "for zone in zones:\n",
    "    zone_counts[zone] = 0\n",
    "\n",
    "for i, tup in enumerate(dirs):\n",
    "    dir, state = tup\n",
    "    train_coco = f'{dir}/annotations/instances_default.json'\n",
    "    train_data_dir = f'{dir}/images/default'\n",
    "\n",
    "    my_dataset = TreeLabel(root=train_data_dir,\n",
    "                            annotation=train_coco,\n",
    "                            transforms=get_transform()\n",
    "                            )\n",
    "    \n",
    "    my_dataset.prep_zone_buckets(zones, 'california_image_zones.csv')\n",
    "    for zone in my_dataset.by_zone:\n",
    "        zone_counts[zone] += len(my_dataset.by_zone[zone])\n",
    "\n",
    "for zone, count in zone_counts.items():\n",
    "    print(zone, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../Treework/filtered_imported_data/KarnatakaTrees4', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees3', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees2', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees5', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees0', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees6', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees1', 'Karnataka'), ('../Treework/filtered_imported_data/KarnatakaTrees7Partial', 'Karnataka')]\n"
     ]
    }
   ],
   "source": [
    "# get all directories to copy over\n",
    "dirs = []\n",
    "\n",
    "for file in os.listdir('../Treework/filtered_imported_data'):\n",
    "    if file == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    if file[:file.find(\"Trees\")] == 'Karnataka':\n",
    "        dirs.append((f'../Treework/filtered_imported_data/{file}', file[:file.find(\"Trees\")]))\n",
    "\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "NORTH EAST TRANSITION 0\n",
      "NORTH EAST DRY 142\n",
      "NORTHERN DRY 304\n",
      "CENTRAL DRY 621\n",
      "EASTERN DRY 787\n",
      "SOUTHERN DRY 175\n",
      "SOUTHERN TRANSITION 498\n",
      "WESTERN TRANSITION 146\n",
      "HILL 20\n",
      "COASTAL 131\n"
     ]
    }
   ],
   "source": [
    "zones = ['NORTH EAST TRANSITION', 'NORTH EAST DRY', 'NORTHERN DRY', 'CENTRAL DRY', 'EASTERN DRY', \n",
    "         'SOUTHERN DRY', 'SOUTHERN TRANSITION', 'WESTERN TRANSITION', 'HILL', 'COASTAL']\n",
    "zone_counts = {}\n",
    "for zone in zones:\n",
    "    zone_counts[zone] = 0\n",
    "\n",
    "for i, tup in enumerate(dirs):\n",
    "    dir, state = tup\n",
    "    train_coco = f'{dir}/annotations/instances_default.json'\n",
    "    train_data_dir = f'{dir}/images/default'\n",
    "\n",
    "    my_dataset = TreeLabel(root=train_data_dir,\n",
    "                            annotation=train_coco,\n",
    "                            transforms=get_transform()\n",
    "                            )\n",
    "    \n",
    "    my_dataset.prep_zone_buckets(zones, 'karnataka_image_zones.csv')\n",
    "    for zone in my_dataset.by_zone:\n",
    "        zone_counts[zone] += len(my_dataset.by_zone[zone])\n",
    "\n",
    "for zone, count in zone_counts.items():\n",
    "    print(zone, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n",
      "[]\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# create the correct sections for COCO format\n",
    "img_written = 0\n",
    "ann_written = 0\n",
    "\n",
    "test_dir = 'test_karnataka_only_ann'\n",
    "train_dir = 'train_karnataka_only_ann'\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "shutil.rmtree(test_dir)\n",
    "shutil.rmtree(train_dir)\n",
    "os.mkdir(test_dir)\n",
    "os.mkdir(f'{test_dir}/images')\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(f'{train_dir}/images')\n",
    "\n",
    "for i, tup in enumerate(dirs):\n",
    "    dir, state = tup\n",
    "    train_coco = f'{dir}/annotations/instances_default.json'\n",
    "    train_data_dir = f'{dir}/images/default'\n",
    "\n",
    "    my_dataset = TreeLabel(root=train_data_dir,\n",
    "                            annotation=train_coco,\n",
    "                            transforms=get_transform()\n",
    "                            )\n",
    "    \n",
    "    test = []\n",
    "    train = []\n",
    "    # split data 10%/90%\n",
    "    for j in range(len(my_dataset.ids)):\n",
    "        if random.random() < 0.1:\n",
    "            test.append(j)\n",
    "        else:\n",
    "            train.append(j)\n",
    "\n",
    "    imgs_test = my_dataset.export_images(img_written, test, state=state)\n",
    "    imgs_train = my_dataset.export_images(img_written, train, state=state)\n",
    "\n",
    "    anns_test = my_dataset.export_annotations(ann_written, test, img_written)\n",
    "    anns_train = my_dataset.export_annotations(ann_written, train, img_written)\n",
    "\n",
    "    img_written += len(imgs_test) + len(imgs_train) + 10000\n",
    "    ann_written += len(anns_test) + len(anns_train) + 10000\n",
    "\n",
    "    with open(f\"{test_dir}/annotations_img.txt\", 'a') as f:\n",
    "        for j, img in enumerate(imgs_test):\n",
    "            if i != 0 or j != 0:\n",
    "                f.write(',')\n",
    "            f.write(f\"{json.dumps(img)}\")\n",
    "\n",
    "    with open(f\"{test_dir}/annotations_ann.txt\", 'a') as f:\n",
    "        for j, ann in enumerate(anns_test):\n",
    "            if i != 0 or j != 0:\n",
    "                f.write(',')\n",
    "            f.write(f\"{json.dumps(ann)}\")\n",
    "\n",
    "    with open(f\"{train_dir}/annotations_img.txt\", 'a') as f:\n",
    "        for j, img in enumerate(imgs_train):\n",
    "            if i != 0 or j != 0:\n",
    "                f.write(',')\n",
    "            f.write(f\"{json.dumps(img)}\")\n",
    "\n",
    "    with open(f\"{train_dir}/annotations_ann.txt\", 'a') as f:\n",
    "        for j, ann in enumerate(anns_train):\n",
    "            if i != 0 or j != 0:\n",
    "                f.write(',')\n",
    "            f.write(f\"{json.dumps(ann)}\")\n",
    "\n",
    "    # copy images to their respective directories\n",
    "    for j in test:\n",
    "        file = my_dataset.coco.loadImgs(my_dataset.ids[j])[0]['file_name']\n",
    "        shutil.copy(f'{dir}/images/default/{file}', f'{test_dir}/images/{file}')\n",
    "\n",
    "    for j in train:\n",
    "        file = my_dataset.coco.loadImgs(my_dataset.ids[j])[0]['file_name']\n",
    "        shutil.copy(f'{dir}/images/default/{file}', f'{train_dir}/images/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3080\n"
     ]
    }
   ],
   "source": [
    "print(img_written - 10000 * len(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge COCO formatted data\n",
    "with open(f'{test_dir}/annotations.json', 'w') as f1:\n",
    "    f1.write('{\"licenses\":[{\"name\":\"\",\"id\":0,\"url\":\"\"}],\"info\":{\"contributor\":\"\",\"date_created\":\"\",\"description\":\"\",\"url\":\"\",\"version\":\"\",\"year\":\"\"},\"categories\":[{\"id\":1,\"name\":\"Kejri Tree\",\"supercategory\":\"\"},{\"id\":2,\"name\":\"Low Quality\",\"supercategory\":\"\"}],\"images\":[')\n",
    "    with open(f'{test_dir}/annotations_img.txt', 'r') as f2:\n",
    "        f1.write(f2.read())\n",
    "    f1.write('],\"annotations\":[')\n",
    "    with open(f'{test_dir}/annotations_ann.txt', 'r') as f2:\n",
    "        f1.write(f2.read())\n",
    "    f1.write(']}')\n",
    "\n",
    "with open(f'{train_dir}/annotations.json', 'w') as f1:\n",
    "    f1.write('{\"licenses\":[{\"name\":\"\",\"id\":0,\"url\":\"\"}],\"info\":{\"contributor\":\"\",\"date_created\":\"\",\"description\":\"\",\"url\":\"\",\"version\":\"\",\"year\":\"\"},\"categories\":[{\"id\":1,\"name\":\"Kejri Tree\",\"supercategory\":\"\"},{\"id\":2,\"name\":\"Low Quality\",\"supercategory\":\"\"}],\"images\":[')\n",
    "    with open(f'{train_dir}/annotations_img.txt', 'r') as f2:\n",
    "        f1.write(f2.read())\n",
    "    f1.write('],\"annotations\":[')\n",
    "    with open(f'{train_dir}/annotations_ann.txt', 'r') as f2:\n",
    "        f1.write(f2.read())\n",
    "    f1.write(']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# export masks\n",
    "\n",
    "data_dir = f'{train_dir}/images'\n",
    "annotations = f'{train_dir}/annotations.json'\n",
    "my_dataset = TreeLabel(root=data_dir,\n",
    "                        annotation=annotations,\n",
    "                        transforms=get_transform()\n",
    "                        )\n",
    "my_dataset.export_mask(f'{train_dir}/masks')\n",
    "\n",
    "data_dir = f'{test_dir}/images'\n",
    "annotations = f'{test_dir}/annotations.json'\n",
    "my_dataset = TreeLabel(root=data_dir,\n",
    "                        annotation=annotations,\n",
    "                        transforms=get_transform()\n",
    "                        )\n",
    "my_dataset.export_mask(f'{test_dir}/masks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
